{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pydub import AudioSegment\n","from pydub.silence import detect_nonsilent, detect_silence\n","from pydub.silence import split_on_silence\n","import numpy as np\n","import ffmpeg\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","#adjust target amplitude\n","def match_target_amplitude(sound, target_dBFS):\n","    change_in_dBFS = target_dBFS - sound.dBFS\n","    return sound.apply_gain(change_in_dBFS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"./records/_records.txt\") as f:\n","    contents = f.readlines()\n","onlyfiles = [f for f in listdir(\"./records/\") if isfile(join(\"./records/\", f))]\n","onlyfiles = list(filter(lambda x: \".wav\" in x, onlyfiles))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = []\n","for file in onlyfiles:\n","#Convert wav to audio_segment\n","    name = file[:file.rfind(\".\")]\n","    audio_segment = AudioSegment.from_wav(\"./records/\" + name + \".wav\")\n","\n","    #normalize audio_segment to -20dBFS \n","    normalized_sound = match_target_amplitude(audio_segment, -20.0)\n","    print(\"length of audio_segment = {} seconds\".format(len(normalized_sound)/1000))\n","\n","    #Print detected non-silent chunks, which in our case would be spoken words.\n","    nonsilent_data = detect_silence(normalized_sound, min_silence_len=500, silence_thresh=-25, seek_step=1)\n","\n","    print(\"start, stop\")\n","    flattened = []\n","    combined = []\n","    for tuple in nonsilent_data:\n","        for value in tuple:\n","            flattened.append(value)\n","\n","    flattened = np.array(flattened)\n","\n","    res = list(filter(lambda x: name in x, contents))[0]\n","    mood = 0\n","    if \"bad\" in res:\n","        mood = 0\n","    if \"neutral\" in res:\n","        mood = 1\n","    if \"good\" in res:\n","        mood = 2\n","    flattened_pmeta = [mood, flattened]\n","    flattened_pmeta = np.array(flattened_pmeta)\n","    data.append(flattened_pmeta)\n","\n","data = np.array(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Convert `X` to data frame\n","df = pd.DataFrame(data)\n","\n","# Rename columns\n","df.columns = ['feature_' + str(i + 1) for i in range(df.shape[1])]\n","\n","# Convert the feature with lists inside to long format\n","features = df['feature_2'].explode().to_frame()\n","\n","# Create counter by observation so we can pivot\n","features['observation_id'] = features.groupby(level=0).cumcount()\n","\n","# Convert to dataset and rename all columns\n","features = features.pivot(columns='observation_id', values='feature_2').fillna(0)\n","features = features.add_prefix('list_element_')\n","\n","# Drop `feature_5` from X\n","df.drop(columns='feature_2', axis=1, inplace=True)\n","\n","# Concatenate X and x together\n","df = pd.concat([df, features], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df.drop([\"feature_1\"],axis=1)\n","y = df[\"feature_1\"]\n","y=y.astype('int')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Carry on as before\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size = 0.3, random_state = 44)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.svm import SVC\n","model  = SVC()\n","model.fit(X_train, y_train)\n","predicted = model.predict(X_test)\n","score = model.score(X_test, y_test)\n","score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","model  = GradientBoostingClassifier()\n","model.fit(X_train, y_train)\n","predicted = model.predict(X_test)\n","score = model.score(X_test, y_test)\n","score"]}],"metadata":{"kernelspec":{"display_name":"vad-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1855135fccb1707bec334e86837365987709d56cd03902efc4be1c0cfeb447b9"}}},"nbformat":4,"nbformat_minor":2}
