{"cells":[{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["from pydub import AudioSegment\n","from pydub.silence import detect_nonsilent, detect_silence\n","from pydub.silence import split_on_silence\n","import numpy as np\n","import ffmpeg\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","#adjust target amplitude\n","def match_target_amplitude(sound, target_dBFS):\n","    change_in_dBFS = target_dBFS - sound.dBFS\n","    return sound.apply_gain(change_in_dBFS)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["with open(\"./records/_records.txt\") as f:\n","    contents = f.readlines()\n","only_files = [f for f in listdir(\"./records/\") if isfile(join(\"./records/\", f))]\n","only_files = list(filter(lambda x: \".wav\" in x, only_files))"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["length of audio_segment = 15.12 seconds\n","start, stop\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\ioci\\AppData\\Local\\Temp\\ipykernel_8612\\1362452930.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  flattened_pmeta = np.array(flattened_pmeta)\n"]},{"name":"stdout","output_type":"stream","text":["length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n","length of audio_segment = 15.12 seconds\n","start, stop\n"]}],"source":["data = []\n","for file in only_files:\n","#Convert wav to audio_segment\n","    name = file[:file.rfind(\".\")]\n","    audio_segment = AudioSegment.from_wav(\"./records/\" + name + \".wav\")\n","\n","    #normalize audio_segment to -20dBFS \n","    normalized_sound = match_target_amplitude(audio_segment, -20.0)\n","    print(\"length of audio_segment = {} seconds\".format(len(normalized_sound)/1000))\n","\n","    #Print detected non-silent chunks, which in our case would be spoken words.\n","    nonsilent_data = detect_silence(normalized_sound, min_silence_len=500, silence_thresh=-25, seek_step=1)\n","\n","    print(\"start, stop\")\n","    flattened = []\n","    combined = []\n","    for tuple in nonsilent_data:\n","        for value in tuple:\n","            flattened.append(value)\n","\n","    flattened = np.array(flattened)\n","\n","    res = list(filter(lambda x: name in x, contents))[0]\n","    mood = 0\n","    if \"bad\" in res:\n","        mood = 0\n","    if \"neutral\" in res:\n","        mood = 1\n","    if \"good\" in res:\n","        mood = 2\n","    flattened_pmeta = [mood, flattened]\n","    flattened_pmeta = np.array(flattened_pmeta)\n","    data.append(flattened_pmeta)\n","\n","data = np.array(data)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Convert `X` to data frame\n","df = pd.DataFrame(data)\n","\n","# Rename columns\n","df.columns = ['feature_' + str(i + 1) for i in range(df.shape[1])]\n","\n","# Convert the feature with lists inside to long format\n","features = df['feature_2'].explode().to_frame()\n","\n","# Create counter by observation so we can pivot\n","features['observation_id'] = features.groupby(level=0).cumcount()\n","\n","# Convert to dataset and rename all columns\n","features = features.pivot(columns='observation_id', values='feature_2').fillna(0)\n","features = features.add_prefix('list_element_')\n","\n","# Drop `feature_5` from X\n","df.drop(columns='feature_2', axis=1, inplace=True)\n","\n","# Concatenate X and x together\n","df = pd.concat([df, features], axis=1)"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature_1</th>\n","      <th>list_element_0</th>\n","      <th>list_element_1</th>\n","      <th>list_element_2</th>\n","      <th>list_element_3</th>\n","      <th>list_element_4</th>\n","      <th>list_element_5</th>\n","      <th>list_element_6</th>\n","      <th>list_element_7</th>\n","      <th>list_element_8</th>\n","      <th>list_element_9</th>\n","      <th>list_element_10</th>\n","      <th>list_element_11</th>\n","      <th>list_element_12</th>\n","      <th>list_element_13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>658</td>\n","      <td>2928</td>\n","      <td>3738</td>\n","      <td>4464</td>\n","      <td>4575</td>\n","      <td>12190</td>\n","      <td>12282</td>\n","      <td>15120</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3615</td>\n","      <td>6289</td>\n","      <td>13969</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3316</td>\n","      <td>3866</td>\n","      <td>5962</td>\n","      <td>9068</td>\n","      <td>15120</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>526</td>\n","      <td>9772</td>\n","      <td>10615</td>\n","      <td>15120</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>919</td>\n","      <td>1504</td>\n","      <td>2190</td>\n","      <td>3259</td>\n","      <td>5553</td>\n","      <td>8547</td>\n","      <td>9677</td>\n","      <td>14410</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  feature_1  list_element_0  list_element_1  list_element_2  list_element_3  \\\n","0         1             658            2928            3738            4464   \n","1         1               0            3615            6289           13969   \n","2         1               0            3316            3866            5962   \n","3         1             526            9772           10615           15120   \n","4         1             919            1504            2190            3259   \n","\n","   list_element_4  list_element_5  list_element_6  list_element_7  \\\n","0            4575           12190           12282           15120   \n","1               0               0               0               0   \n","2            9068           15120               0               0   \n","3               0               0               0               0   \n","4            5553            8547            9677           14410   \n","\n","   list_element_8  list_element_9  list_element_10  list_element_11  \\\n","0               0               0                0                0   \n","1               0               0                0                0   \n","2               0               0                0                0   \n","3               0               0                0                0   \n","4               0               0                0                0   \n","\n","   list_element_12  list_element_13  \n","0                0                0  \n","1                0                0  \n","2                0                0  \n","3                0                0  \n","4                0                0  "]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["df.head(5)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["X = df.drop([\"feature_1\"],axis=1)\n","y = df[\"feature_1\"]\n","y=y.astype('int')"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["# Carry on as before\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size = 0.35, random_state = 42)"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/plain":["0.6111111111111112"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.svm import SVC\n","model  = SVC()\n","model.fit(X_train, y_train)\n","predicted = model.predict(X_test)\n","score = model.score(X_test, y_test)\n","score"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/plain":["0.5"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","model  = GradientBoostingClassifier()\n","model.fit(X_train, y_train)\n","predicted = model.predict(X_test)\n","score = model.score(X_test, y_test)\n","score"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["SVC average: 0.4941963407436553\n","GBC average: 0.4945898091678143\n"]}],"source":["SVC_scores = []\n","GBC_scores = []\n","\n","from statistics import mean\n","\n","for i in range(1, 300):\n","    X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size = 0.33, random_state = i)\n","\n","    model  = SVC()\n","    model.fit(X_train, y_train)\n","    predicted = model.predict(X_test)\n","    SVC_scores.append(model.score(X_test, y_test))\n","\n","    model  = GradientBoostingClassifier()\n","    model.fit(X_train, y_train)\n","    predicted = model.predict(X_test)\n","    GBC_scores.append(model.score(X_test, y_test))\n","\n","print(f'SVC average: {mean(SVC_scores)}')\n","print(f'GBC average: {mean(GBC_scores)}')"]}],"metadata":{"kernelspec":{"display_name":"vad-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1855135fccb1707bec334e86837365987709d56cd03902efc4be1c0cfeb447b9"}}},"nbformat":4,"nbformat_minor":2}
